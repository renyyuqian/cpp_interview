### 数据类型

#### string

​		String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。

​		SDS 不仅可以保存文本数据，还可以保存二进制数据； SDS 获取字符串长度的时间复杂度是 O(1)；Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。

![1736510597053](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736510597053.png)

​		

#### list

​		List 列表是简单的字符串列表，**按照插入顺序排序**，可以从头部或尾部向 List 列表添加元素。

​		List 类型的底层数据结构是由**双向链表或压缩列表**实现的

![1736510690874](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736510690874.png)

#### hash

​		Hash 是一个键值对（key - value）集合，其中 value 的形式如：

​		value=[{field1，value1}，...{fieldN，valueN}] 。Hash 特别适合用于存储对象。

​		Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

![1736510855816](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736510855816.png)



#### set

​		Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。

​		Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

![1736510846445](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736510846445.png)

#### zset

​		Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。

​		有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。

​		Zset 类型的底层数据结构是由**压缩列表或跳表**实现的

![1736510869362](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736510869362.png)

### 数据结构

#### SDS

![1736511039934](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511039934.png)

#### 双向链表

​			![1736511080209](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511080209.png)

#### 压缩链表

​		压缩列表是 Redis 为了节约内存而开发的，它是**由连续内存块组成的顺序型数据结构**，有点类似于数组。

![1736511189728](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511189728.png)

***zlbytes***，记录整个压缩列表占用对内存字节数；

***zltail***，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；

***zllen***，记录压缩列表包含的节点数量；

**zlend***，标记压缩列表的结束点，固定值 0xFF（十进制255）。

***prevlen***，记录了「前一个节点」的长度，目的是为了实现从后向前遍历

***encoding***，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。

***data***，记录了当前节点的实际数据，类型和长度都由 `encoding` 决定

#### 哈希表

![1736511266048](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511266048.png)

#### 整数集合

​		整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现。

![1736511334525](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511334525.png)

![1736511341088](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511341088.png)

#### 跳表

**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表**，

![1736511369347](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511369347.png)

#### quicklist

​		 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。

![1736511423256](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511423256.png)

#### listpack

![1736511443751](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511443751.png)

### 持久化篇

#### AOF日志

​		**AOF 文件的内容是操作命令；**

​			Redis 每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，然后重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，相当于恢复了缓存数据。

​		![1736511564902](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511564902.png)

​		这种保存写操作命令到日志的持久化方式，就是 Redis 里的 **AOF(Append Only File)** 持久化功能，**注意只会记录写操作命令，读操作命令是不会被记录的**，因为没意义。**默认不开启**

Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。

​		**避免额外的检查开销。**因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。

​		**不会阻塞当前写操作命令的执行**，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。

AOF 持久化功能也不是没有潜在风险。

​		执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有**丢失的风险**。

​		由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是**可能会给「下一个」命令带来阻塞风险**。

​		因为将命令写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程）， 这两个操作是同步的。

###### 三种写回策略

​	![1736511865676](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736511865676.png)

##### AOF 重写机制

​		AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。

​		如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。

​		所以，Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

​		AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

​		重写机制的**妙处**在于，尽管某个键值对被多条写命令反复修改，**最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对**，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量。最后在重写工作完成后，将新的 AOF 文件覆盖现有的 AOF 文件。

###### AOF 后台重写

​		Redis 的**重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的**，这么做可以达到两个好处：

​				子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；

​				子进程带有主进程的数据副本,这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。

​		触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。

​		但是子进程重写过程中，主进程依然可以正常处理命令。

​		如果此时**主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的**。



​			重写过程中，主进程修改了key-value，此时这个key-value数据和子进程的数据不一致了，怎么办？Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:

​		执行客户端发来的命令；   将执行后的写命令追加到 「AOF 缓冲区」；  将执行后的写命令追加到 「AOF 重写缓冲区」； 

 当子进程完成 AOF 重写工作后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

​		将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；

​		新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。



#### RDB快照	

​		**RDB 文件的内容是二进制数据。**

##### 快照怎么用？

Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`，他们的区别就在于是否在「主线程」里执行：

​			执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；

​			执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

Redis 的快照是**全量快照**，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。

所以可以认为，执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。

##### 执行快照时，数据能被修改吗？

​		Redis 依然**可以继续处理操作命令**的，也就是数据是能被修改的。那具体如何做到到呢？关键的技术就在于**写时复制技术（Copy-On-Write, COW）**

#### RDB 和 AOF 合体

尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握

​		如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；

​		如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。

**混合使用 AOF 日志和内存快照**，也叫混合持久化。

混合持久化工作在 **AOF 日志重写过程**

当开启了混合持久化时，在 AOF 重写日志时，`fork` 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

也就是说，使用了混合持久化，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样**加载的时候速度会很快**。

加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得**数据更少的丢失**。



### 功能篇

##### 过期删除策略

​		Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

###### 如何设置过期时间？

​		expire <key> <n>： 设置 key 在 n 秒后过期，比如 expire key 100 表示设置 key 在 100 秒后过期；

​		pexpire <key> <n>： 设置 key 在 n 毫秒后过期，比如 pexpire key2 100000 

​		set <key> <value> ex <n>    设置键值对的时候，同时指定过期时间（精确到秒）；

​		set <key> <value> px <n>  设置键值对的时候，同时指定过期时间（精确到毫秒）；

​		TTL <key>   查看存活时间

​		PERSIST <key>  取消过期时间

###### 如何判定 key 已过期了？	

​		每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

​		如果不在，则正常读取键值；   如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

###### 过期删除策略有哪些？

​		定时删除；    惰性删除；   定期删除

​		定时删除策略的做法是，**在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。**

![1736684278162](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736684278162.png)

​		惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

![1736684331519](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736684331519.png)

​		定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**

![1736684362600](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736684362600.png)

​	**Redis 选择「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

##### 内存淘汰策略

​		当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。

###### Redis 内存淘汰策略有哪些？

***不进行数据淘汰的策略***

​		**noeviction**（Redis3.0之后，默认的内存淘汰策略）  ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。

***进行数据淘汰的策略***

​	又可以细分为「**在设置了过期时间的数据中进行淘汰**」和「**在所有数据范围内进行淘汰**」这两类策略。

在设置了过期时间的数据中进行淘汰

​		**volatile-random**：随机淘汰设置了过期时间的任意键值；

​		**volatile-ttl**：优先淘汰更早过期的键值。

​		**volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；

​		**volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；

在所有数据范围内进行淘汰

​		**allkeys-random**：随机淘汰任意键值;

​		**allkeys-lru**：淘汰整个键值中最久未使用的键值；

​    	**allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

###### 什么是 LRU 算法？

​		**LRU** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。

​		传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。

传统的 LRU 算法存在两个问题：

​		需要用链表管理所有的缓存数据，这会带来额外的空间开销；

​		当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

###### 什么是 LFU 算法？

​		LFU 全称是 Least Frequently Used 翻译为**最近最不常用**，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。

​		所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。



### 高可用篇

![1736762960111](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736762960111.png)



![1736762994982](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736762994982.png)

#### 主从复制

##### 第一次同步

主从服务器间的第一次同步的过程可分为三个阶段：

​		第一阶段是建立链接、协商同步；

​		第二阶段是主服务器同步数据给从服务器；

​		第三阶段是主服务器发送新写操作命令给从服务器。

![1736763086367](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736763086367.png)

*第一阶段：建立链接、协商同步*

​		执行了 replicaof 命令后，从服务器就会给主服务器发送`psync` 命令，表示要进行数据同步。

​		psync 命令包含两个参数，分别是**主服务器的 runID** 和**复制进度 offset**。

​		**runID**，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 "?"。

​		offset，表示复制的进度，第一次同步时，其值为 -1。

​		主服务器收到 psync 命令后，会用 `FULLRESYNC` 作为响应命令返回给对方

​		并且这个响应命令会带上两个参数：主服务器的 **runID** 和主服务器目前的复制进度 **offset**。从服务器收到响应后，会记录这两个值。

​		FULLRESYNC 响应命令的意图是采用**全量复制**的方式，也就是主服务器会把所有的数据都同步给从服务器。

​		所以，第一阶段的工作时为了全量复制做准备。

*第二阶段：主服务器同步数据给从服务器*

​		接着，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。

​		从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。

​		主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。 但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。

​		那么为了保证主从服务器的数据一致性，**主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里**：

​			主服务器生成 RDB 文件期间；  主服务器发送 RDB 文件给从服务器期间； 从服务器加载 RDB 文件期间；

*第三阶段：主服务器发送新写操作命令给从服务器*

​		在主服务器生成的 RDB 文件发送完，从服务器收到 RDB 文件后，丢弃所有旧数据，将 RDB 数据载入到内存。完成 RDB 的载入后，会回复一个确认消息给主服务器。

​		接着，主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令，这时主从服务器的数据就一致了。

###### 命令传播

​		主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。    后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。	

​		而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

​		上面的这个过程被称为**基于长连接的命令传播**

###### 分摊主服务器的压力

​		第一次同步，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。

​		主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：

​				由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；

​				传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。

![1736763605264](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736763605264.png)



通过这种方式，**主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器**。



###### 增量复制

​	   网络断开又恢复后，从主从服务器会采用**增量复制**的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。

主要有三个步骤：

​		从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；

​		主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；

​		然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

**主服务器怎么知道要将哪些增量数据发送给从服务器呢？**

​		**repl_backlog_buffer**，是一个「**环形**」缓冲区，用于主从服务器断连后，从中找到差异的数据；

​		**replication offset**，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「*写* 」到的位置，从服务器使用 slave_repl_offset 来记录自己「*读*」到的位置。

**那 repl_backlog_buffer 缓冲区是什么时候写入的呢？**

​		在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。

​		网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：

​				如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**增量同步**的方式；如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**全量同步**的方式。

​		当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。

主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**。

#### 哨兵

###### 为什么要有哨兵机制？

​		在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。

​		**哨兵（Sentinel）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

###### 哨兵机制是如何工作的？

​		哨兵节点主要负责三件事情：**监控、选主、通知**。

###### 如何判断主节点真的故障了？

​		哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。

​		如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。

​		为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**（*最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。 同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

###### 由哪个哨兵进行主从故障转移？

​		为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以**哨兵是以哨兵集群的方式存在的**。

​		需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。  候选者投票  >= **quorum** 

​		**quorum** **的值建议设置为哨兵个数的二分之一加 1**， 例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且**哨兵节点的数量应该是奇数**。



###### 主从故障转移的过程是怎样的？

![1736764711163](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736764711163.png)

主从故障转移操作包含以下四个步骤：

​		在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。

​		让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；

​		将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；

​		继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；



**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。

在主从集群中，主节点上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。  哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。

### 缓存

​		用户的数据一般都是存储于数据库，数据库的数据是落在磁盘上的，磁盘的读写速度可以说是计算机里最慢的硬件了。

​		当用户的请求，都访问数据库的话，请求数量一上来，数据库很容易就奔溃的了，所以为了避免用户直接访问数据库，会用 Redis 作为缓存层。

​		因为 Redis 是内存数据库，我们可以将数据库的数据缓存在 Redis 里，相当于数据缓存在内存，内存的读写速度比硬盘快好几个数量级，这样大大提高了系统性能。

​		引入了缓存层，就会有缓存异常的三个问题，分别是**缓存雪崩、缓存击穿、缓存穿透**。

#### 血崩

​		通常我们为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。

![1736773015020](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736773015020.png)

​		那么，当**大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机**时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是**缓存雪崩**的问题。

![1736773338644](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736773338644.png)

###### 大量数据同时过期

​		针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法有下面这几种

*1. 均匀设置过期时间*

​		如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，**给这些数据的过期时间加上一个随机数**，这样就保证数据不会在同一时间过期。

*2. 互斥锁*

​		当业务线程在处理用户请求时，**如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存**（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。

​		实现互斥锁的时候，最好设置**超时时间**，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。

*3. 后台更新缓存*

​		业务线程不再负责更新缓存，缓存也不设置有效期，而是**让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新**。

​		事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为**当系统内存紧张的时候，有些缓存数据会被“淘汰”**，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。

解决上面的问题的方式有两种。

​		第一种方式，后台线程不仅负责定时更新缓存，而且也负责**频繁地检测缓存是否有效**，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。

​		第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），**通过消息队列发送一条消息通知后台线程更新缓存**，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；

###### redis故障宕机

*1. 服务熔断或请求限流机制*

​		因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动**服务熔断**机制，**暂停业务应用对缓存服务的访问，直接返回错误**，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。

​		为了减少对业务的影响，我们可以启用**请求限流**机制，**只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务**，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。

*2. 构建 Redis 缓存高可靠集群*

​		服务熔断或请求限流机制是缓存雪崩发生后的应对方案，我们最好通过**主从节点的方式构建 Redis 缓存高可靠集群**。

​		如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis故障宕机而导致的缓存雪崩问题。

#### 击穿

​		如果缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮, 这就是**缓存击穿**的问题。

![1736774338038](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736774338038.png)



​		互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。

​		不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

#### 穿透

​		当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。

​		当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。

![1736774428258](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736774428258.png)

缓存穿透的发生一般有这两种情况：

​		业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；

​		黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

1、非法请求的限制；

​		当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。

2、缓存空值或者默认值

​		当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。

3、使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；

​		

#### 缓存和数据库不一致的问题

##### **Cache Aside 策略**

​		中文名字**旁路缓存策略**。

​		不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。

![1736682991765](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1736682991765.png)

写策略时

​		**先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题**。

​		理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，**但是在实际中，这个问题出现的概率并不高**。

​		**因为缓存的写入通常要远远快于数据库的写入**，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。

​		**「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的**。

###### 消息队列重试机制

引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

​		如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。

​		如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

###### 订阅 MySQL binlog，再操作缓存

​		**先更新数据库，再删缓存**的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。

​		于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。