###  键入网址到网页显示，发生了什么

![1737289293101](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737289293101.png)

##### 孤单小弟 —— HTTP

**浏览器做的第一步工作是解析 URL**

 		对输入的网址进行URL解析，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。

![1737289519098](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737289519098.png)

##### 真实地址查询 —— DNS

​		通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 `Web` 服务器。 这时候就需要**服务器对应的IP地址**， 因为操作系统发送消息时，必须提供通信对象的IP地址。

​		所以，有一种服务器就专门保存了Web服务器域名与IP的对应关系，它就是**DNS服务器**。

​		DNS 中的域名都是用**句点**来分隔的，比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。

​		在域名中，**越靠右**的位置表示其层级**越高**。

![1737289974496](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737289974496.png)

​		根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。

​		**域名解析流程**

​		![1737290157522](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737290157522.png)

##### 指南好帮手 —— 协议栈

​		通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**。

​		协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。

###### 可靠传输-----TCP 

![1737290529357](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737290529357.png)

​		三次握手目的是**保证双方都有发送和接收的能力**。

​		生成请求消息，可以封装成一个TCP数据段。

###### 远程定位-----IP   I

​		TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成**网络包**发送给通信对象。

​		在 IP 协议里面需要有**源地址 IP** 和 **目标地址 IP**：

​				1、源地址IP，即是客户端输出的 IP 地址；

​				2、目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。

​		在TCP为HTTP请求加上头部之后，再加上IP头部，其中目标地址是通过 DNS 域名解析得到的 Web 服务器 IP。

###### 两点传输 —— MAC

​		生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 **MAC 头部**。

​		MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。

​		在 MAC 包头里需要**发送方 MAC 地址**和**接收方目标 MAC 地址**，用于**两点之间的传输**。

**发送方**的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。

**接收方**的 MAC 地址就有点复杂了，需要 `ARP` 协议帮我们找到路由器的 MAC 地址。

![1737291756663](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737291756663.png)

###### 出口 —— 网卡

​		网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将**数字信息转换为电信号**，才能在网线上传输，也就是说，这才是真正的数据发送过程。

​		负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**。

​		网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**。

![1737291941035](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737291941035.png)

​		起始帧分界符是一个用来表示包起始位置的标记；

​		末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏；

最后网卡会将包转为电信号，通过网线发送出去。

##### 送别者 —— 交换机

​		首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。

​		然后通过包末尾的 `FCS` 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。

​		**交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口**。

##### 出境大门 —— 路由器

​		网络包经过交换机之后，现在到达了**路由器**，并在此被转发到下一个路由器或目标设备。

​		这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。

##### 互相扒皮——服务器与客户端

​		数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。

​		接着继续扒开数据包的 **IP 头**，发现 IP 地址符合，根据 IP 头中协议项，知道自己**上层是 TCP 协议**。

​		于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 **ACK**，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。

​		于是，服务器自然就知道是 **HTTP 进程想要这个包**，于是就**将包发给 HTTP 进程**。

​		服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页**封装在 HTTP 响应报文**里。

​		HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。

​		穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。

​		最后跳到了客户端的城门把守的**路由器**，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的**交换机**，再由**交换机**转发到客户端。

​		客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！

​		于是，客户端开始扒皮，**把收到的数据包的皮扒剩 HTTP 响应报文后**，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！

​		最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。

### HTTP

#### HTTP基本概念

​		HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

​		 HTTP **协议**，我们可以这么理解 ，HTTP 是一个用在计算机世界里的**协议**。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理方式（**行为约定和规范**）。

​		HTTP 是一个在计算机世界里**专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**

###### HTTP 常见的状态码

​	![1737357829838](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737357829838.png)

###### HTTP 常见字段

***Host* 字段**

​		客户端发送请求时，用来指定服务器的域名。

***Content-Length 字段***

​		服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。

​		**HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题**。

***Connection 字段***

​		`Connection` 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。

​		HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。

###### *Content-Type 字段*

​		`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。

***Content-Encoding 字段***

​		`Content-Encoding` 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

#### GET 与 POST

###### GET

​		**GET 的语义是从服务器获取指定的资源**，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。

![1737358635077](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737358635077.png)

###### POST

​		**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。

![1737358645191](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737358645191.png)

###### 安全和幂等

​		在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。

​		所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

​		**GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签**。

​		**POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。

#### HTTP 缓存技术

​		对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。

​		所以，避免发送 HTTP 请求的方法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。

​		HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

###### 强制缓存

​		强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

###### 协商缓存

​		当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。

​		**协商缓存就是与服务端协商之后，d通过协商结果来判断是否使用本地缓存**。

​		**协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。

![1737359272245](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737359272245.png)

#### HTTP 特性

​		HTTP 常见到版本有 HTTP/1.1，HTTP/2.0，HTTP/3.0，不同版本的 HTTP 特性是不一样的。

​		HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；

​		HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

###### HTTP/1.1 

​	    HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。

***简单***

​		HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。

***灵活和易于扩展***

​		HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。

***应用广泛和跨平台***

HTTP 协议里有优缺点一体的**双刃剑**，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。

***无状态双刃剑***		

​		无状态的**好处**，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。

​		无状态的**坏处**，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。

​		对于无状态的问题，解法方案有很多种，其中比较简单的方式用 **Cookie** 技术

​		`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。

​		相当于，**在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了**，

![1737359916660](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737359916660.png)

***明文传输双刃剑***

​		明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。

​		但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于**信息裸奔**。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那**你号没了**。

***不安全***

​		通信使用明文（不加密），内容可能会被窃听。比如，**账号信息容易泄漏，那你号没了。**

​		不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多，那你钱没了**

​		无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告，视觉污染，眼没了。**

HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

***性能***

​		HTTP 协议是基于 **TCP/IP**，并且使用了「**请求 - 应答**」的通信模式，所以性能的关键就在这**两点**里。

***长连接***

​		早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销。

​		为了解决上述 TCP 连接问题，HTTP/1.1 提出了**长连接**的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。

​		当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。

***管道网络传输***

​		HTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。

​		即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**

​		举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求，如下图：

![1737360216578](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737360216578.png)

​		但是**服务器必须按照接收请求的顺序发送对这些管道化请求的响应**。

​		如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。

​		所以，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。

***队头阻塞***

「请求 - 应答」的模式会造成 HTTP 的性能问题。为什么呢？

​			因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」，好比上班的路上塞车。

![1737360285388](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737360285388.png)

**优化技术**

​		利用缓存减少重复的HTTP请求，客户端在进行HTTP请求后，会把该请求的资源缓存在本地。 根据客户端的响应码来判断缓存的数据是否更新。

​		将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；

​		对于 HTTP 的请求和响应，通常 HTTP 的响应的数据大小会比较大，也就是服务器返回的资源会比较大。于是，我们可以考虑对响应的资源进行**压缩**，这样就可以减少响应的数据大小，从而提高网络传输的效率。



###### HTTPS

​		HTTPS 解决了 HTTP **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。**篡改风险**，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。**冒充风险**，比如冒充淘宝网站，用户钱容易没。

HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了上述的风险：

​		**信息加密**：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。

​		**校验机制**：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。

​		**身份证书**：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

**HTTPS 是如何解决上面的三个风险的？**

​		**混合加密**的方式实现信息的**机密性**，解决了窃听的风险。

​		**摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。

​		将服务器公钥放入到**数字证书**中，解决了冒充的风险。



###### HTTP/2

​		尽管对 HTTP/1.1 协议的优化手段如此之多，但是效果还是不尽人意，因为这些手段都是对 HTTP/1.1 协议的“外部”做优化，**而一些关键的地方是没办法优化的，比如请求-响应模型、头部巨大且重复、并发连接耗时、服务器不能主动推送等，要改变这些必须重新设计 HTTP 协议，于是 HTTP/2 就出来了！**

​		HTTP/2 出来的目的是为了改善 HTTP 的性能。 协议升级有一个很重要的地方，就是要**兼容**老版本的协议，否则新协议推广起来就相当困难，所幸 HTTP/2 做到了兼容 HTTP/1.1。

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

***头部压缩***

​		HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。

​		这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

![1737375980904](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737375980904.png)

静态表只包含了 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建**动态表**，它的 Index 从 `62` 起步，会在编码解码的时候随时更新。

​		使得动态表生效有一个前提：**必须同一个连接上，重复传输完全相同的 HTTP 头部**。如果消息字段在 1 个连接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就无法被充分利用了。



***二进制格式***

​		HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧（Headers Frame）和数据帧（Data Frame）**。增加了数据传输的效率。

![1737362360223](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737362360223.png)

HTTP/2 **二进制帧**的结构如下图：

![1737376367059](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737376367059.png)

帧头（Frame Header）很小，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Frame Playload）的**长度**。

帧长度后面的一个字节是表示**帧的类型**，HTTP/2 总共定义了 10 种类型的帧，一般分为**数据帧**和**控制帧**两类，如下表格：

![1737376417114](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737376417114.png)

***并发传输***

​		我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了**队头阻塞**的问题。

​		如果响应迟迟不来，那么后续的请求是无法发送的，也造成了**队头阻塞**的问题。

​		而 HTTP/2 就很牛逼了，通过 Stream 这个设计，**多个 Stream 复用一条 TCP 连接，达到并发的效果**，解决了 HTTP/1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。

![1737362452474](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737362452474.png)

​		从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；

​		因此，我们可以得出个结论：多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。

​		在 HTTP/2 连接上，**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而**同一 Stream 内部的帧必须是严格有序的**。



***服务器主动推送资源***

​		HTTP/1.1 不支持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资源。

​		比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：

![1737376840849](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737376840849.png)

如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。



###### HTTP/3 

​		HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。

​		队头阻塞；    TCP 与 TLS 的握手时延迟；  网络迁移需要重新连接；

***QUIC 协议的特点***

​		我们深知，UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。

​		而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。

​		当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 **QUIC 协议**，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。

QUIC 协议的优点有很多，这里举例几个，比如：

***无队头阻塞***

​		QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。

​		 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。

​		而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

​		所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。

![1737377257860](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737377257860.png)

***更快的连接建立***

​		对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、OpenSSL 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。

​		HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

​		但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 **QUIC 内部包含了 TLS**，它在**自己的帧会携带 TLS** **里的“记录”**，再加上 QUIC 使用的是 **TLS 1.3**，因此仅**需 1 个 RTT** 就可以「同时」**完成建立连接与密钥协商**，甚至在**第二次连接**的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。

***连接迁移***

​		 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

![1737377562913](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737377562913.png)

HTTP/3 帧头只有两个字段：类型和长度。HTTP/3 在头部压缩算法这一方面也做了升级，升级成了 **QPACK**。



#### 为什么要用RPC

**HTTP 协议用的好好的，为什么还要用 RPC 协议？**

RPC 和 HTTP 区别比较明显的几个点：

###### 服务发现

​		首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道 **IP 地址和端口**。这个找到服务对应的 IP 端口的过程，其实就是**服务发现**。

​		在 **HTTP** 中，你知道服务的域名，就可以通过 **DNS 服务**去解析得到它背后的 IP 地址，默认 80 端口。

​		而 **RPC** 的话，就有些区别，一般会有专门的**中间服务**去保存服务名和IP信息，比如 **Consul 或者 Etcd，甚至是 Redis**。想要访问某个服务，就去这些中间服务去获得 IP 和端口信息。由于 DNS 也是服务发现的一种，所以也有基于 DNS 去做服务发现的组件，比如**CoreDNS**。

###### 底层连接形式

​		以主流的 **HTTP/1.1** 协议为例，其默认在建立底层 TCP 连接之后会一直保持这个连接，之后的请求和响应都会复用这条连接。

​		而 **RPC** 协议，也跟 HTTP 类似，也是通过建立 TCP 长链接进行数据交互，但不同的地方在于，RPC 协议一般还会再建个**连接池**，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，**用完放回去，下次再复用**，可以说非常环保。

![1737378547848](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737378547848.png)

**由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给 HTTP 加个连接池**，比如 **Go** 就是这么干的。

###### 传输的内容

​		基于 TCP 传输的消息，说到底，无非都是**消息头 Header 和消息体 Body。**

​		**Header** 是用于标记一些特殊信息，其中最重要的是**消息体长度**。

​		**Body** 则是放我们真正需要传输的内容，而这些内容只能是二进制 01 串。

​		这个将结构体转为二进制数组的过程就叫**序列化**，反过来将二进制数组复原成结构体的过程叫**反序列化**

![1737378613503](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737378613503.png)

​	HTTP在 Body 这块，它使用 **Json** 来**序列化**结构体数据。  有非常多的**冗余**，显得**非常啰嗦**。 

​	而 RPC，因为它定制化程度更高，可以采用体积更小的 Protobuf 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样考虑各种浏览器行为，比如 302 重定向跳转啥的。**因此性能也会更好一些，这也是在公司内部微服务中抛弃 HTTP，选择使用 RPC 的最主要原因。**

![1737378713493](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737378713493.png)

![1737378770385](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737378770385.png)

#### 为什么要用WebSocket

​		我们知道 TCP 连接的两端，**同一时间里**，**双方**都可以**主动**向对方发送数据。这就是所谓的**全双工**。

​		而现在使用最广泛的`HTTP/1.1`，也是基于TCP协议的，**同一时间里**，客户端和服务器**只能有一方主动**发数据，这就是所谓的**半双工**。

​		我们平时刷网页，一般都是在浏览器上刷的，一会刷刷图文，这时候用的是 **HTTP 协议**，一会打开网页游戏，这时候就得切换成我们新介绍的 **WebSocket 协议**。

​		为了兼容这些使用场景。浏览器在 **TCP 三次握手**建立连接之后，都**统一使用 HTTP 协议**先进行一次通信。

​		如果此时是**普通的 HTTP 请求**，那后续双方就还是老样子继续用普通 HTTP 协议进行交互，这点没啥疑问。

​		如果这时候是**想建立 WebSocket 连接**，就会在 HTTP 请求里带上一些**特殊的header 头**，如下：

```http
Connection: Upgrade
Upgrade: WebSocket
Sec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\r\n
```

这些 header 头的意思是，浏览器想**升级协议（Connection: Upgrade）**，并且**想升级成 WebSocket 协议（Upgrade: WebSocket）**。同时带上一段**随机生成的 base64 码（Sec-WebSocket-Key）**，发给服务器。

​		如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 base64 码，用某个**公开的**算法变成另一段字符串，放在 HTTP 响应的 `Sec-WebSocket-Accept` 头里，同时带上`101状态码`，发回给浏览器。HTTP 的响应如下：

```http
HTTP/1.1 101 Switching Protocols\r\n  // 101指协议切换
Sec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n
Upgrade: WebSocket\r\n
Connection: Upgrade\r\n
```

之后，浏览器也用同样的**公开算法**将`base64码`转成另一段字符串，如果这段字符串跟服务器传回来的**字符串一致**，那验证通过。

​		就这样经历了一来一回两次 HTTP 握手，WebSocket就建立完成了，后续双方就可以使用 webscoket 的数据格式进行通信了。

WebSocket和HTTP一样都是基于TCP的协议。**经历了三次TCP握手之后，利用 HTTP 协议升级为 WebSocket 协议**。

###### WebSocket消息格式

![1737379311570](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737379311570.png)

**opcode字段**：这个是用来标志这是个**什么类型**的数据帧。

**payload字段**： 存放的是我们**真正想要传输的数据的长度**，单位是**字节**。比如你要发送的数据是`字符串"111"`，那它的长度就是`3`。

**payload data字段**： 这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。

###### WebSocket的使用场景

​		WebSocket完美继承了 TCP 协议的**全双工**能力，并且还贴心的提供了解决粘包的方案。

​		它适用于**需要服务器和客户端（浏览器）频繁交互**的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。

![1737379482388](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737379482388.png)

### TCP

#### 基本概念

​	**头部格式**

![1737443717123](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737443717123.png)

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

**面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的

**可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

**字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。



TCP连接是 用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 **Socket、序列号和窗口大小**称为连接。





#### TCP连接建立

​		TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的**。三次握手的过程如下图：

![1737445209947](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737445209947.png)



​		一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 **`LISTEN`** 状态

​		客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1`，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 **`SYN-SENT`** 状态。

​		服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`）,将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 **`SYN-RCVD`** 状态。

​		客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` , 最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 **`ESTABLISHED`** 状态.

​		服务端收到客户端的应答报文后，也进入 **`ESTABLISHED`** 状态。

​		**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，

**为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接。**

***避免历史连接***

​		TCP 使用三次握手建立连接的**最主要原因就是防止「历史连接」初始化了连接**。**如果是两次握手连接，就无法阻止历史连接**，那为什么 TCP 两次握手为什么无法阻止历史连接呢？

​		主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

***同步双方初始序列号***

​		序列号能够保证数据包不重复、不丢弃和按序传输。

​		TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

​				接收方可以去除重复的数据；  

​				接收方可以根据数据包的序列号按序接收；

​				可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

​	通过三次握手可以保证**双方的初始序列号能被可靠的同步。**

***避免资源浪费***

​		如果只有「两次握手」，当客户端发生的 `SYN` 报文在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，**由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接**，这会造成什么情况呢？

​		服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**



**如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题**。

MTU：一个网络包的最大长度，以太网中一般为 `1500` 字节；

`MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；

​		**当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。

​		 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。



###### 第一次握手丢失

​		当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 `SYN_SENT` 状态。

​		如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。

​		会设置重传次数，如果大于了这个重传次数，客户端会断开连接。



###### 第二次握手丢失

​		当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 `SYN_RCVD` 状态。

第二次握手的 `SYN-ACK` 报文其实有两个目的 ：

​		第二次握手里的 ACK，是对第一次握手的确认报文；

​		第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；

​		因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。

​		如果第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。

因此，当第二次握手丢失了，客户端和服务端都会重传：

​		客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 `tcp_syn_retries`内核参数决定；

​		服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 `tcp_synack_retries` 内核参数决定。



###### 第三次握手丢失了

​		客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

​		因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

​		注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。



###### SYN攻击

​		TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。

***半连接队列和全连接队列***

​		在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

​		半连接队列，也称 SYN 队列；

​		全连接队列，也称 accept 队列；

![1737617413426](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737617413426.png)

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。



SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

避免 SYN 攻击方式， 减少SYN-ACK重传次数； 利用cookie



#### TCP连接断开

​		TCP 断开连接是通过**四次挥手**方式。双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：

![1737617656351](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737617656351.png)

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。**主动关闭连接的，才有 TIME_WAIT 状态。**

***为什么挥手需要四次？***

​		关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。

​		服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

###### 第一次挥手丢失

​		触发超时重传，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

###### 第二次挥手丢失

​		ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

​		这意味着对于调用 close 函数关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭，如下图

![1737618014095](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737618014095.png)

但是注意，如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。

此时，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 `FIN_WAIT2` 状态

![1737618186304](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737618186304.png)

###### 第三次挥手丢失

​		当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

​		服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。

​		如果迟迟收不到这个 ACK，，服务端会重发FIN报文，与客户端重发 FIN 报文的重传次数控制方式是一样的。

###### 第四次挥手丢失

​		当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。

​		TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。

​		客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。

***为什么TIME_WAIT等待的时间是2MSL***

​		`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

​		因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

***MSL 与 TTL 的区别***： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

***TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：***

​		 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

​		可以看到 **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。

​		`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。



***为什么需要 TIME_WAIT 状态？***

​		主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

两个原因：

​		防止历史连接中的数据，被后面相同四元组的连接错误的接收；

​		保证「被动关闭连接」的一方，能被正确的关闭；



***服务器出现大量 CLOSE_WAIT 状态的原因有哪些？***

​		CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。

​		所以，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接**。

原因如下：

​		没有将服务端 socket 注册到 epoll；  客户连接到来时，没有调用accept获取已经连接的socket；	没有将已连接的 socket 注册到 epoll；  对方关闭连接时。我方没有调用close。



针对已经连接的TCP客户端，服务器会定义一个时间段，每隔一个时间间隔，发送一个探测报文，来探测客户端是否正常。 这就是**TCP的保活机制**。



#### Socket

***accept 发生在三次握手的哪一步？***

![1737634868881](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737634868881.png)

​		客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。

***客户端调用 close 了，连接是断开的流程是什么？***

![1737634947224](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737634947224.png)

***没有 accept，能建立 TCP 连接吗***？

​		**可以的**。   accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

***没有 listen，能建立 TCP 连接吗？***

​		**可以的**。  客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**



#### 重传机制

​		TCP 实现可靠传输的方式之一，是通过序列号与确认应答。

TCP 针对数据包丢失的情况，会用**重传机制**解决。

###### 超时重传

​		重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是我们常说的**超时重传**。

​		时机： 数据包丢失，确认应答丢失

RTT 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

![1737635376027](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737635376027.png)

**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

###### 快速重传

​		TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。

![1737635471063](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737635471063.png)

###### SACK 方法

​		还有一种实现重传机制的方式叫：`SACK`（ Selective Acknowledgment）， **选择性确认**。

​		这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

###### Duplicate SACK

​		**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

![1737635602433](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737635602433.png)

#### 滑动窗口

***引入窗口概念的原因***

​		我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。

​		这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。

​		如果你说完一句话，我在处理其他事情，没有及时回复你，你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。

​		这样的传输方式有一个缺点：数据包的**往返时间越长，通信的效率就越低**。

​		为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。

​		窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

​		窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

#### 流量控制

​		发送方不能无脑的发数据给接收方，要考虑接收方处理能力。

​		如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

​		为了解决这种现象发生，**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

​		流量控制是避免「发送方」的数据填满「接收方」的缓存，接收方不能够很快的应答发送确认，导致发送方重传。

​		流量控制是点到点的通信，是一个端到端的问题。

#### 拥塞控制

​		目的就是**避免「发送方」的数据填满整个网络。**  拥塞控制是应对整个计算机网络的问题。

​		**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

###### 慢启动

​		TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？

​		慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

![1737636681093](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737636681093.png)

可以看出慢启动算法，发包的个数是**指数性的增长**。

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

​		当 `cwnd` < `ssthresh` 时，使用慢启动算法。

​		当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

###### 拥塞避免算法

​		当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

​		一般来说 `ssthresh` 的大小是 `65535` 字节。

​		那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

![1737636835077](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737636835077.png)

​		我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。

​		就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

​		当触发了重传机制，也就进入了「拥塞发生算法」。

###### 拥塞发生

​		当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传

  当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh 和 cwnd 的值会发生变化：

  ​		`ssthresh` 设为 cwnd/2；  `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）

  ![1737636993980](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737636993980.png)

  接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

- 快速重传

  当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

  TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

  ​		cwnd = cwnd/2，也就是设置为原来的一半;

  ​		ssthresh = cwnd;

  ​		进入快速恢复算法

  ###### 快恢复

  ​		快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

  ​		正如前面所说，进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

  ​		cwnd = cwnd/2，也就是设置为原来的一半;

  ​		ssthresh = cwnd;

  快速恢复算法的变化过程如下图：

![1737637240592](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737637240592.png)



也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。

#### 半连接队列和全连接队列

- 半连接队列，也称 SYN 队列；

- 全连接队列，也称 accept 队列；

服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，

接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。**

#### 如何理解字节流？

之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的**发送方的机制不同**，也就是问题原因在发送方。

**先来说说为什么 UDP 是面向报文的协议？**

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。

操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文**，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。

**再来说说为什么 TCP 是面向字节流的协议？**

当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。

因此，**我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议**。

当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。

#### 如何解决粘包？

粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

- 固定长度的消息；

即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。

- 特殊字符作为边界；

我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。

- 自定义消息结构

我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。

#### 为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？

是为了防止历史报文被下一个相同四元组的连接接收。

**TCP 四次挥手中的 TIME_WAIT 状态不是会持续 2 MSL 时长，历史报文不是早就在网络中消失了吗？**

是的，如果能正常四次挥手，由于 TIME_WAIT 状态会持续 2 MSL 时长，历史报文会在下一个连接之前就会自然消失。

但是来了，我们并不能保证每次连接都能通过四次挥手来正常关闭连接。

假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：

​		客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。

​		紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接

​		在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。

可以看到，如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。

**客户端和服务端的初始化序列号不一样不是也会发生这样的事情吗？**

是的，即使客户端和服务端的初始化序列号不一样，也会存在收到历史报文的可能。

但是我们要清楚一点，历史报文能否被对方接收，还要看该历史报文的序列号是否正好在对方接收窗口内，如果不在就会丢弃，如果在才会接收。

如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文。

![1739877130347](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1739877130347.png)

#### SYN 报文什么时候情况下会被丢弃？

**坑爹的 tcp_tw_recycle**

​		TCP 四次挥手过程中，主动断开连接方会有一个 TIME_WAIT 的状态，这个状态会持续 2 MSL 后才会转变为 CLOSED 状态。

​		在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。

​		**如果客户端（发起连接方）的 TIME_WAIT 状态过多**，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，但是被使用的端口，还是可以继续对另外一个服务器发起连接的。

但是 TIME_WAIT 状态也不是摆设作用，它的作用有两个：

​		防止具有相同四元组的旧数据包被收到，也就是防止历史连接中的数据，被后面的连接接受，否则就会导致后面的连接收到一个无效的数据，

​		保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭;

net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；

**半连接队列满了**

当服务器造成syn攻击，就有可能导致 **TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃**。

但是，**如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包**。

syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。

![1739877618894](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1739877618894.png)

这里给出几种防御 SYN 攻击的方法：

- 减少 SYN+ACK 重传次数
- 开启 tcp_syncookies 功能
- 增大半连接队列；

**全连接队列满了**

**在服务端并发处理大量请求时，如果 TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了 ，这时后续的连接就会被丢弃，这样就会出现服务端请求数量上不去的现象。**

要解决这个问题，我们可以：

调大 accpet 队列的最大长度，调大的方式是通过**调大 backlog 以及 somaxconn 参数。**

检查系统或者代码为什么调用 accept() 不及时；

#### 已建立连接的TCP，收到SYN会发生什么？

一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？

**1. 客户端的 SYN 报文里的端口号与历史连接不相同**

如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。

*那旧连接里处于 Established 状态的服务端最后会怎么样呢？*

如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。

如果服务端一直没有发送数据包给客户端，在超过一段时间后，TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。

**2. 客户端的 SYN 报文里的端口号与历史连接相同**

如果客户端恢复后，发送的 SYN 报文中的源端口号跟上一次连接的源端口号一样，也就是处于 Established 状态的服务端收到了这个 SYN 报文。

![1739878056056](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1739878056056.png)

![1739878166794](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1739878166794.png)













### UDP

**头部格式**

![1737444999928](C:\Users\renyu\AppData\Roaming\Typora\typora-user-images\1737444999928.png)